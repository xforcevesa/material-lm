{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Transformer\n",
    "## Tokenizer"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bfddbf5d1ed34d9a"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 15043, 2787, 29991]\n",
      "<s> Hello World!\n",
      "32000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['http_proxy'] = 'http://127.0.0.1:8889'\n",
    "os.environ['https_proxy'] = 'http://127.0.0.1:8889'\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('FlagAlpha/Llama2-Chinese-7b-Chat')\n",
    "text = 'Hello World!'\n",
    "input_id = tokenizer(text)\n",
    "print(input_id['input_ids'])\n",
    "decoded_text = tokenizer.decode(input_id['input_ids'])\n",
    "print(decoded_text)\n",
    "print(len(tokenizer.vocab))\n",
    "# for token in input_id['input_ids']:\n",
    "#     decoded_token = tokenizer.decode([token])\n",
    "#     print(f'{token}: {decoded_token}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T12:34:25.015203Z",
     "start_time": "2024-03-30T12:34:24.202920Z"
    }
   },
   "id": "b4c4fe647fc1eb95",
   "execution_count": 49
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Embedding"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4bdb692955a4bc5b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torch\n",
    "input_id = torch.tensor(input_id['input_ids'])\n",
    "# print(input_id)\n",
    "# input_id_onehot = F.one_hot(input_id, num_classes=tokenizer.vocab_size)\n",
    "# print(input_id_onehot.shape)\n",
    "\n",
    "# id_demo = torch.tensor([1, 4, 5, 2, 3, 0])\n",
    "# print(F.one_hot(id_demo, num_classes=6))\n",
    "\n",
    "# embedding = nn.Embedding(\n",
    "#     num_embeddings=tokenizer.vocab_size,\n",
    "#     embedding_dim=512\n",
    "# )\n",
    "# input_id_embedding = embedding(input_id)\n",
    "# print(input_id_embedding.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T12:34:25.022658Z",
     "start_time": "2024-03-30T12:34:25.017563Z"
    }
   },
   "id": "b38b129f66146b68",
   "execution_count": 50
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Positional Encoding"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d3150a6f4a532a2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, batch_size: int):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.batch_size = batch_size\n",
    "        pe = torch.zeros(batch_size, d_model)\n",
    "        position = torch.arange(0, batch_size, dtype=torch.float32).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return x + (self.pe[:, :x.shape[1], :]).requires_grad_(False)\n",
    "\n",
    "# positional_encoding = PositionalEncoding(512, 1)\n",
    "# input_id_embedding = positional_encoding(input_id_embedding.reshape([1, *input_id_embedding.shape])).reshape(input_id_embedding.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T12:34:25.037253Z",
     "start_time": "2024-03-30T12:34:25.024612Z"
    }
   },
   "id": "c874688c683bda4f",
   "execution_count": 51
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Encoder\n",
    "### MultiHeadAttention"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f186f4872fcd0dd"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import einops\n",
    "\n",
    "# wk = torch.ones(512, 512)\n",
    "# wq = torch.ones(512, 512)\n",
    "# wv = torch.ones(512, 512)\n",
    "# wo = torch.ones(512, 512)\n",
    "# def attention(x):\n",
    "#     key = einops.rearrange(x @ wk, 'n (h d) -> h n d', h=16)\n",
    "#     query = einops.rearrange(x @ wk, 'n (h d) -> h n d', h=16)\n",
    "#     value = einops.rearrange(x @ wk, 'n (h d) -> h n d', h=16)\n",
    "#     attn = (query @ key.transpose(1, 2)) / (512 ** 0.5)\n",
    "#     attn = F.softmax(attn, dim=-1)\n",
    "#     return einops.rearrange(attn @ value, 'h n d -> n (h d)') @ wo\n",
    "# print(attention(input_id_embedding))\n",
    "\n",
    "# linear(x) = x @ A + b \n",
    "\n",
    "class Attention(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_model: int, num_heads: int, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.wk = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.wq = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.wv = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.wo = nn.Linear(d_model, d_model, bias=False)\n",
    "        \n",
    "    def forward(self, x, k=None, mask=None):\n",
    "        key = einops.rearrange(self.wk(x if k is None else k), 'b n (h d) -> b h n d', h=self.num_heads)\n",
    "        query = einops.rearrange(self.wq(x if k is None else k), 'b n (h d) -> b h n d', h=self.num_heads)\n",
    "        value = einops.rearrange(self.wv(x), 'b n (h d) -> b h n d', h=self.num_heads)\n",
    "        attn = (query @ key.transpose(-2, -1)) / (self.d_model ** 0.5)\n",
    "        if mask is not None:\n",
    "            attn = torch.masked_fill(attn, mask, -1e9)\n",
    "        attn = F.softmax(attn, dim=-1)\n",
    "        attn = einops.rearrange(attn @ value, 'b h n d -> b n (h d)')\n",
    "        return self.wo(attn)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T12:34:25.049986Z",
     "start_time": "2024-03-30T12:34:25.040111Z"
    }
   },
   "id": "12b3b628ed519dfb",
   "execution_count": 52
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Encoder / Decoder"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4fcfbd0a9d2bf931"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_model: int, num_heads: int, batch_size: int):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        self.attn = Attention(d_model, num_heads)\n",
    "        self.norm_a = nn.LayerNorm(d_model)\n",
    "        self.norm_b = nn.LayerNorm(d_model)\n",
    "        self.norm_c = nn.LayerNorm(d_model)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(d_model, d_model)\n",
    "        )\n",
    "        self.attn_cross = Attention(d_model, num_heads)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor, k=None, mask=None):\n",
    "        # x.shape [batch_size, seq_len, embed_dim]\n",
    "        x = self.norm_a(self.attn(x)) + x\n",
    "        if mask is not None:\n",
    "            x = self.norm_b(self.attn_cross(x, k, mask)) + x\n",
    "        x = self.norm_c(self.ffn(x)) + x\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T12:34:25.058195Z",
     "start_time": "2024-03-30T12:34:25.051671Z"
    }
   },
   "id": "ef50aed272a45d0e",
   "execution_count": 53
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Transformer"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6c505cb88e0276d3"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "cb16c05bcfaeb693"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 20, 512])\n"
     ]
    }
   ],
   "source": [
    "class Transformer(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_model: int, num_heads: int, batch_size: int, num_layers: int):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        self.batch_size = batch_size\n",
    "        self.num_layers = num_layers\n",
    "        self.embed = nn.Embedding(\n",
    "            num_embeddings=tokenizer.vocab_size,\n",
    "            embedding_dim=d_model\n",
    "        )\n",
    "        self.pe = PositionalEncoding(d_model, batch_size)\n",
    "        self.encoders = nn.ModuleList([\n",
    "            Encoder(d_model=d_model, num_heads=num_heads, batch_size=batch_size) \n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        self.decoders = nn.ModuleList([\n",
    "            Encoder(d_model=d_model, num_heads=num_heads, batch_size=batch_size) \n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(d_model, d_model),\n",
    "            nn.Softmax(dim=-1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, src: torch.Tensor, tgt: torch.Tensor, mask=None):\n",
    "        src = self.embed(src)\n",
    "        tgt = self.embed(tgt)\n",
    "        src = self.pe(src)\n",
    "        tgt = self.pe(tgt)\n",
    "        encoder_outputs = src\n",
    "        for encoder in self.encoders:\n",
    "            encoder_outputs = encoder(encoder_outputs)\n",
    "        decoder_outputs = tgt\n",
    "        if mask is not None:\n",
    "            mask = torch.zeros(self.d_model // self.num_heads, self.d_model // self.num_heads)\n",
    "        for decoder in self.decoders:\n",
    "            decoder_outputs = decoder(decoder_outputs, encoder_outputs, mask)\n",
    "        output = self.mlp(decoder_outputs)\n",
    "        return output\n",
    "        \n",
    "transformer = Transformer(d_model=512, num_heads=16, batch_size=20, num_layers=5)\n",
    "src = torch.randint(0, tokenizer.vocab_size - 1, (20, 20))\n",
    "tgt = torch.randint(0, tokenizer.vocab_size - 1, (20, 20))\n",
    "output = transformer(src, tgt)\n",
    "print(output.size())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T12:34:25.457367Z",
     "start_time": "2024-03-30T12:34:25.060765Z"
    }
   },
   "id": "14026575332ade19",
   "execution_count": 54
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
